from typing import Union, List, Tuple, Dict
from pydantic import BaseModel
import json
import pandas as pd
import re
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain_community.chat_models import ChatOllama
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from rag_tool_memory_save_noprint import run_filtered_rag
from Final_Trend import KeywordAnalyzer
from Final_evaluator import Agent3
from writer_tool4_new import generate_technical_draft

llm = ChatOllama(model="qwen2.5:7b", temperature=0.0)

def safe_result_summary(result):
    if isinstance(result, pd.DataFrame):
        return result.to_markdown(index=False)
    elif isinstance(result, list):
        return "\n".join(str(x) for x in result[:5])
    elif isinstance(result, dict):
        return json.dumps(result, indent=2, ensure_ascii=False)
    else:
        return str(result)


def extract_json_from_text(text: str) -> str:
    json_pattern = r'\{[\s\S]*\}'
    match = re.search(json_pattern, text)
    if match:
        return match.group(0)
    raise ValueError("JSON \ud615\uc2dd\uc774 \uc544\ub2d9\ub2c8\ub2e4.")


embedding_model = OllamaEmbeddings(model="bge-m3")
vectorstore = Chroma(
    persist_directory="/Users/heejinyang/python/streamlit/Evaluator_DB",
    embedding_function=embedding_model,
)


class PlanExecute(BaseModel):
    input: str
    tools: List[str] = []
    sub_queries: Dict[str, Union[str, List[str]]] = {}
    results: Dict[str, str] = {}
    response: Union[str, None] = None
    log: List[str] = []
    llm: ChatOllama = llm  # ì „ì—­ ê³µìœ  LLM


tool_selector_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì ì ˆí•œì§€ íŒë‹¨í•˜ì„¸ìš”.

[ë„êµ¬ ì„¤ëª…]
- patent_searcher: ì‚¬ìš©ìì˜ ê¸°ìˆ ì  ì§ˆë¬¸ì— ë§ëŠ” íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ê³  ê·¸ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.
- patent_trend_analyzer: íŠ¹ì • í‚¤ì›Œë“œ, ì¶œì›ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ íŠ¹í—ˆ ì¶œì› ê±´ìˆ˜ ë° íŠ¸ë Œë“œë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
- patent_evaluator: ì£¼ì–´ì§„ ê¸°ìˆ  ì£¼ì œì— ëŒ€í•œ íŠ¹í—ˆë“¤ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ìì‚¬ê°€ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ì§€í‘œë¥¼ í† ëŒ€ë¡œ ê²½ìŸì‚¬ì˜ ì¤‘ìš” ê´€ë ¨ íŠ¹í—ˆë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.
- tech_writer: ê¸°ìˆ  ê°œìš”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  ì„¤ëª…ì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{query}" 

âœ… ì„ íƒ ì§€ì¹¨:
- í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì›ì¹™ì…ë‹ˆë‹¤.
- ë‹¨, ì§ˆë¬¸ì´ ë‘ ê°œ ì´ìƒì˜ ë„êµ¬ê°€ í˜‘ì—…í•´ì•¼ë§Œ í•´ê²°ë˜ëŠ” ê²½ìš°, ë„êµ¬ë¥¼ ë³µìˆ˜ ì„ íƒí•˜ì„¸ìš”.
- patent_searcherì˜ ê²½ìš° ì§ˆë¬¸ì´ ë‘ ê°€ì§€ ì´ìƒì˜ ê³ ë„í™”ëœ íŠ¹í—ˆ ê²€ìƒ‰ì´ ìš”êµ¬ë˜ëŠ” ê²½ìš°, patent_searcherë¥¼ ë‘ ë²ˆ ë°˜ë³µ í˜¸ì¶œí•´ë„ ë©ë‹ˆë‹¤.
- patent_searcherê°€ 2ë²ˆ ì„ íƒëœ ê²½ìš°ëŠ” **ê·¸ë¦¬ê³ **, **ë˜ëŠ”** í˜¹ì€ ë§ˆì¹¨í‘œë‚˜ ì½¤ë§ˆë¡œ ì„œë¡œ ë‹¤ë¥¸ ì„±ê²©ì˜ ê¸°ìˆ ì— ëŒ€í•´ì„œ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°ì— ë‘ ë²ˆ í˜¸ì¶œí•˜ë©´ë¼.

ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœì˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{"tools": ["patent_searcher"]}}
ë˜ëŠ”
{{"tools": ["patent_searcher", "patent_evaluator"]}}
ë˜ëŠ”
{{"tools": ["patent_searcher", "patent_searcher"]}}
ë˜ëŠ”
{{"tools": ["patent_searcher", "patent_trend_analyzer"]}}
ë˜ëŠ”
{{"tools": ["patent_searcher", "patent_trend_analyzer","patent_evaluator"]}}
ë˜ëŠ”
{{"tools": ["tech_writer"]}}
""")

tool_selector_chain = tool_selector_prompt | llm


def tool_selector(state: PlanExecute):
    print("\nğŸ›  [STEP 1] ë„êµ¬ ì„ íƒ ì‹œì‘")
    response = tool_selector_chain.invoke({"query": state.input})
    raw = response.content.strip()
    print("ğŸ›  ë„êµ¬ ì„ íƒ ì‘ë‹µ ì›ë³¸:\n", raw)
    try:
        json_text = extract_json_from_text(raw)
        parsed = json.loads(json_text)
    except Exception as e:
        raise ValueError(f"[tool_selector] JSON íŒŒì‹± ì‹¤íŒ¨: {e}\nì›ë³¸ ì‘ë‹µ:\n{raw}")
    print(f"ğŸ›  ì„ íƒëœ ë„êµ¬: {parsed['tools']}")
    return {"tools": parsed["tools"], "log": state.log + [f"ğŸ”§ ì„ íƒëœ ë„êµ¬: {parsed['tools']}"]}


sub_query_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì„ íƒëœ ë„êµ¬ ëª©ë¡ì…ë‹ˆë‹¤.
ê° ë„êµ¬ì— ëŒ€í•´ í•˜ë‚˜ì˜ ì§ˆì˜ë¥¼ ìƒì„±í•˜ì„¸ìš”. 
ë‹¨,
- patent_searcherëŠ” ì§ˆë¬¸ì„ ë°˜ì˜í•˜ì—¬ ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ ì „ë‹¬, ì´ë•Œ ì‚¬ìš©ìê°€ ê¸°ìˆ ì ì¸ ë‚´ìš©ì„ ë‹´ê¸°ì— ë‚´ìš©ì„ ì„ì˜ëŒ€ë¡œ ëˆ„ë½í•˜ì§€ ì•Šì•˜ìœ¼ë©´ í•´.**ê·¸ë¦¬ê³ ** **ë˜ëŠ”** ë° ë§ˆì¹¨í‘œ ì½¤ë§ˆë¡œ êµ¬ë¶„í•´ì„œ ë‘ ê°€ì§€ ê¸°ìˆ ì— ëŒ€í•´ì„œ ì§ˆë¬¸ì„ í•˜ëŠ” ê²½ìš°ëŠ” ë‚˜ëˆ„ì–´ì„œ íŒŒì•…í•´.
- patent_trend_analyzerëŠ” '**íŠ¹í—ˆ ì¶œì› ë™í–¥ ë¶„ì„**ì„ ìœ„í•´ ì‚¬ìš©ì sub queryì— ìˆëŠ” í‚¤ì›Œë“œ ë‹¨ì–´ì™€ ì—°ë„ë¥¼ ì‚¬ìš©í•´ì„œ ì „ë‹¬ (ì˜ˆ1) êµ¬ë™ëª¨í„° ê´€ë ¨ 2020ë…„ ì´í›„ ì¶œì› ë™í–¥. ì˜ˆ2) í˜„ëŒ€ìë™ì°¨ì˜ ë°°í„°ë¦¬ ê´€ë ¨ ì—°ë„ë³„ ì¶œì›ë™í–¥.)
- patent_evaluatorëŠ” ê²½ìŸì‚¬ ë° íŠ¹ì • ê¸°ìˆ ì— ëŒ€í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œë¥¼ 1~2ê°œ ì‚¬ìš©í•´ì„œ ì „ë‹¬. ì´ë•Œ í‚¤ì›Œë“œëŠ” ê¸°ìˆ  ë‹¨ìœ„ì—¬ì•¼í•˜ê³  ìì—°ì–´ í˜•íƒœë¡œ ì „ë‹¬í•´ì•¼í•¨.
- tech_writerëŠ” "ì´ˆì•ˆì‘ì„±" ì´ë¼ê³  ì „ë‹¬.

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{query}"

ì„ íƒëœ ë„êµ¬ ëª©ë¡:
{tools}


ë³µí•© ì§ˆì˜ì˜ ê²½ìš° ì¶œë ¥ ì˜ˆì‹œ:
1) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ì˜ ë°°í„°ë¦¬ íš¨ìœ¨ ê°œì„  ê¸°ìˆ  ê´€ë ¨ íŠ¹í—ˆìˆì–´? ê´€ë ¨ ê¸°ìˆ ì— ëŒ€í•œ ì—°ë„ë³„ ì¶œì› ë™í–¥ë„ ì•Œë ¤ì¤˜"ë¼ë©´,
{{
  "sub_queries": {{
    "patent_searcher": "ì „ê¸°ì°¨ì˜ ë°°í„°ë¦¬ íš¨ìœ¨ ê°œì„  ê¸°ìˆ  ê´€ë ¨ íŠ¹í—ˆ",
    "patent_trend_analyzer": "ì „ê¸°ì°¨ê³¼ì—´ ë°©ì§€ ê´€ë ¨ ì—°ë„ë³„ ì¶œì› ë™í–¥"
  }}
}}
ë˜ëŠ”
2) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ ë‚´ ëƒ‰ê°ìˆ˜ íë¦„ì„ ì œì–´í•˜ê¸° ìœ„í•´ êµ¬ì¶•í•œ ìë™ ëª¨ë‹ˆí„°ë§ ê¸°ìˆ ì„ ì•Œê³  ì‹¶ê³  ì—´ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë‚´ë¶€ ì¿¨ë§ì‹œìŠ¤í…œì„ ì´ìš©í•˜ëŠ” ê¸°ìˆ ì„ ì•Œê³  ì‹¶ë‹¤" ê³  í•œë‹¤ë©´, ë‘ ê°€ì§€ ê¸°ìˆ  í•µì‹¬ ë‚´ìš©ì´ ë“¤ì–´ìˆìœ¼ë¯€ë¡œ,
{{
  "sub_queries": {{
    "patent_searcher": "ì „ê¸°ì°¨ ë‚´ ëƒ‰ê°ìˆ˜ íë¦„ì„ ì œì–´í•˜ê¸° ìœ„í•´ êµ¬ì¶•í•œ ìë™ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê¸°ìˆ , ì—´ ê´€ë¦¬ë¥¼ ìœ„í•œ ì°¨ì²´ ë‚´ ì¿¨ë§ ì‹œìŠ¤í…œì„ ì´ìš©í•˜ëŠ” ê¸°ìˆ ",
  }}
}}
ë˜ëŠ”                                                    
3) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ì˜ ë³€ì†ê°ì„ ì¢‹ê²Œ í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ íŠ¹í—ˆ ìˆì–´? ê´€ë ¨ ê¸°ìˆ ì„ ì¶œì›í•œ í˜„ëŒ€ìë™ì°¨ì˜ íŠ¹í—ˆ í‰ê°€ë¥¼ í•´ì¤˜"ë¼ë©´,
{{
  "sub_queries": {{
    "patent_searcher": "ë³€ì†ê°ì„ ì£¼ë©° ìŠ¹ì°¨ê°ì„ ë†’ì¸ ê¸°ìˆ ",
    "patent_evaluator": "ë³€ì†ê° ë° ì†ë„ ì œì–´ "
  }}
}}
í˜•ì‹ìœ¼ë¡œ **ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”. ë°˜ë“œì‹œ JSONì´ ì™„ì „í•œ í˜•ì‹({{ ì¤‘ê´„í˜¸ ë‹«í˜ í¬í•¨ }})ì´ì–´ì•¼ í•˜ë©°, ë¬¸ìì—´ keyì™€ valueëŠ” ë°˜ë“œì‹œ ìŒë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.**
""")

sub_query_chain = sub_query_prompt | llm


def tool_query_planner(state: PlanExecute):
    print("\nğŸ§© [STEP 2] Sub-query ìƒì„± ì‹œì‘")
    result = sub_query_chain.invoke({"query": state.input, "tools": ", ".join(state.tools)})
    print("ğŸ§© Sub-query ì‘ë‹µ ì›ë³¸:\n", result.content)
    try:
        json_text = extract_json_from_text(result.content)
        parsed = json.loads(json_text)
    except Exception as e:
        raise ValueError(f"âŒ Sub-query ìƒì„± ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:\n{result.content}\n\nì—ëŸ¬: {e}")
    print("ğŸ§© Sub-query ë¶„ë¦¬ ê²°ê³¼:", parsed["sub_queries"])
    return {"sub_queries": parsed["sub_queries"], "log": state.log + [f"ğŸ§© Sub-query ë¶„ë¦¬ ê²°ê³¼: {parsed['sub_queries']}"]}


def execute_tools(state: PlanExecute):
    print("\nâš™ï¸ [STEP 3] ë„êµ¬ ì‹¤í–‰ ì‹œì‘")
    results = {}
    for tool_name, query in state.sub_queries.items():
        print(f"\nâ–¶ ì‹¤í–‰ ë„êµ¬: {tool_name}")
        print(f"â–¶ ì§ˆì˜ ë‚´ìš©: {query}")

        if tool_name == "patent_searcher":
            sub_queries = [q.strip() for q in query.split(",") if q.strip()]
            combined_summary = ""
            for i, sub_q in enumerate(sub_queries, 1):
                print(f"  ğŸ” [patent_searcher] ì„œë¸Œ ì¿¼ë¦¬ {i}: {sub_q}")
                rag_result = run_filtered_rag(
                    vectorstore, embedding_model, sub_q,
                    llm=state.llm, use_bm25=True
                )
                if rag_result is None or not isinstance(rag_result, tuple):
                    # ì—ëŸ¬ ë¡œê·¸ ë‚¨ê¸°ê³  ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ëŒ€ì²´
                    print(f"âš ï¸ run_filtered_ragê°€ ì˜¬ë°”ë¥¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {rag_result!r}")
                    summary = "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    summary, _ = rag_result
                    combined_summary += f"[ì„œë¸Œ ì¿¼ë¦¬ {i}] {sub_q}\n{summary}\n\n"
            results[tool_name] = combined_summary.strip()

        elif tool_name == "patent_trend_analyzer":
            trend_agent = KeywordAnalyzer(
                csv_path="/Users/heejinyang/python/streamlit/Codes/Filtered_final.csv",
                llm=state.llm)
            interpretation = trend_agent.run(query)
            results[tool_name] = safe_result_summary(interpretation)

        elif tool_name == "patent_evaluator":
            evaluator = Agent3(
                csv_path="/Users/heejinyang/python/streamlit/Codes/Filtered_final.csv",
                llm=state.llm)
            interpretation = evaluator.handle(topic_query=query)
            results[tool_name] = interpretation

        elif tool_name == "tech_writer":
            result = generate_technical_draft.invoke({"user_input": query})
            content = result.content if hasattr(result, "content") else str(result)
            results[tool_name] = content

        else:
            results[tool_name] = f"[{tool_name}]ì— ëŒ€í•œ ì‘ë‹µ (Mock ì²˜ë¦¬ë¨)"

        print(f"âœ… {tool_name} ì‹¤í–‰ ì™„ë£Œ")

    print("âš™ï¸ ì „ì²´ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    return {"results": results, "log": state.log + [f"âš™ï¸ ì‹¤í–‰ ì™„ë£Œ: {list(results.keys())}"]}


def post_summary(state: PlanExecute):
    print("\nğŸ§  [STEP 4] ê²°ê³¼ ìš”ì•½ ì‹œì‘")
    merged = "\n\n".join(f"[{tool} ê²°ê³¼]\n{res}" for tool, res in state.results.items())

    if not merged.strip():
        print("âš ï¸ ê²°ê³¼ ì—†ìŒ: post_summary ë‹¨ê³„ì—ì„œ ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"response": "â— ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.", "log": state.log + ["âš ï¸ post_summary: ê²°ê³¼ ì—†ìŒ"]}

    summary_prompt = PromptTemplate.from_template("""

ì•„ë˜ëŠ” ê° ë„êµ¬ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ê²°ê³¼ì…ë‹ˆë‹¤:

{merged}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
ì´ë•Œ, ê° Toolì— ë”°ë¼ ì–´ë–¤ ì •ë³´ê°€ íŒŒì•…ë˜ì—ˆëŠ”ì§€, ì´ë¥¼ í†µí•´ ì–´ë–¤ ì¢…í•©ì  ì‹œì‚¬ì ì„ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ì˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ë•Œ, **ë°˜ë“œì‹œ** í•œêµ­ì–´ë¡œë§Œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
""")
    summary_chain = summary_prompt | state.llm
    result = summary_chain.invoke({"merged": merged})

    print("ğŸ§  ìµœì¢… ì‘ë‹µ ìš”ì•½:\n", result.content.strip())
    return {"response": result.content.strip(), "log": state.log + ["ğŸ§  ìµœì¢… ì¢…í•© ìš”ì•½ ì™„ë£Œ"]}

graph = StateGraph(PlanExecute)
graph.add_node("tool_selector", tool_selector)
graph.add_node("tool_query_planner", tool_query_planner)
graph.add_node("execute", execute_tools)
graph.add_node("post_summary", post_summary)

graph.add_edge(START, "tool_selector")
graph.add_edge("tool_selector", "tool_query_planner")
graph.add_edge("tool_query_planner", "execute")
graph.add_edge("execute", "post_summary")
graph.add_edge("post_summary", END)

app = graph.compile(checkpointer=MemorySaver())
