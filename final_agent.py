from typing import Union, List, Tuple, Dict
from pydantic import BaseModel
import json
import pandas as pd
import re
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain_community.chat_models import ChatOllama
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from rag_tool_memory_save_noprint import run_filtered_rag
from Final_Trend import KeywordAnalyzer
from Final_evaluator import Agent3
from writer_tool4_new import generate_technical_draft


llm = ChatOllama(model="qwen2.5:7b", temperature=0.0)

def safe_result_summary(result):
    if isinstance(result, pd.DataFrame):
        return result.to_markdown(index=False)
    elif isinstance(result, list):
        return "\n".join(str(x) for x in result[:5]) 
    elif isinstance(result, dict):
        return json.dumps(result, indent=2, ensure_ascii=False)
    else:
        return str(result)


def extract_json_from_text(text: str) -> str:
    json_pattern = r'\{[\s\S]*\}'
    match = re.search(json_pattern, text)
    if match:
        return match.group(0)
    raise ValueError("JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")

# âœ… Embedding + Vectorstore ì´ˆê¸°í™”
embedding_model = OllamaEmbeddings(model="bge-m3")
vectorstore = Chroma(
    persist_directory="/Users/heejinyang/python/streamlit/chroma_db_streamlit",
    embedding_function=embedding_model,
)

# âœ… ìƒíƒœ ì •ì˜
class PlanExecute(BaseModel):
    input: str
    tools: List[str] = []
    sub_queries: Dict[str, Union[str, List[str]]] = {}
    sub_queries_generated: bool = False  # âœ… ì—¬ê¸°ì— ì¶”ê°€!
    results: Dict[str, str] = {}
    response: Union[str, None] = None
    log: List[str] = []
    llm: ChatOllama = llm # ì „ì—­ ê³µìœ  llm

# âœ… Tool Selector (ë„êµ¬ ì„¤ëª… í¬í•¨)
tool_selector_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì ì ˆí•œì§€ íŒë‹¨í•˜ì„¸ìš”.

[ë„êµ¬ ì„¤ëª…]
- patent_searcher: ì‚¬ìš©ìì˜ ê¸°ìˆ ì  ì§ˆë¬¸ì— ë§ëŠ” íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ê³  ê·¸ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.
- patent_trend_analyzer: íŠ¹ì • í‚¤ì›Œë“œ, ì¶œì›ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ íŠ¹í—ˆ ì¶œì› ê±´ìˆ˜ ë° íŠ¸ë Œë“œë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
- patent_evaluator: ì£¼ì–´ì§„ ê¸°ìˆ  ì£¼ì œì— ëŒ€í•œ íŠ¹í—ˆë“¤ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ìì‚¬ê°€ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ì§€í‘œë¥¼ í† ëŒ€ë¡œ ê²½ìŸì‚¬ì˜ ì¤‘ìš” ê´€ë ¨ íŠ¹í—ˆë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.
- tech_writer: ê¸°ìˆ  ê°œìš”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  ì„¤ëª…ì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{query}"

âœ… ì„ íƒ ì§€ì¹¨:
- í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì›ì¹™ì…ë‹ˆë‹¤.
- ë‹¨, ì§ˆë¬¸ì´ ë‘ ê°œ ì´ìƒì˜ ë„êµ¬ê°€ í˜‘ì—…í•´ì•¼ë§Œ í•´ê²°ë˜ëŠ” ê²½ìš°, ë„êµ¬ë¥¼ ë³µìˆ˜ ì„ íƒí•˜ì„¸ìš”.
- patent_searcherì˜ ê²½ìš° ì§ˆë¬¸ì´ ë‘ ê°€ì§€ ì´ìƒì˜ ê³ ë„í™”ëœ íŠ¹í—ˆ ê²€ìƒ‰ì´ ìš”êµ¬ë˜ëŠ” ê²½ìš°, patent_searcherë¥¼ ë‘ ë²ˆ ë°˜ë³µ í˜¸ì¶œí•´ë„ ë©ë‹ˆë‹¤.
- patent_searcherê°€ 2ë²ˆ ì„ íƒëœ ê²½ìš°ëŠ” **ê·¸ë¦¬ê³ **, **ë˜ëŠ”** í˜¹ì€ ë§ˆì¹¨í‘œë‚˜ ì½¤ë§ˆë¡œ ì„œë¡œ ë‹¤ë¥¸ ì„±ê²©ì˜ ê¸°ìˆ ì— ëŒ€í•´ì„œ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°ì— ë‘ ë²ˆ í˜¸ì¶œí•˜ë©´ë¼.

âš ï¸ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆì§€ë§‰ ì¤„ì€ "}}" ë¡œ ì •í™•íˆ ë‹«ì•„ì•¼ í•˜ë©°, ì‰¼í‘œ ëˆ„ë½ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
                                                                                                                
ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœì˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{ "tools": ["patent_searcher"] }}
ë˜ëŠ”
{{ "tools": ["patent_searcher", "patent_evaluator"] }}                                                   
ë˜ëŠ” ì‚¬ìš©ìê°€ ë‘ ê°€ì§€ ìƒì´í•œ ê¸°ìˆ ì  ë‚´ìš© ë¶„ì„ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°,                                                        
{{ "tools": ["patent_searcher", "patent_searcher"] }}                                                        
ë˜ëŠ”
{{ "tools": ["patent_searcher", "patent_trend_analyzer"] }}
ë˜ëŠ”
{{ "tools": ["patent_searcher", "patent_trend_analyzer","patent_evaluator"]}}   
ë˜ëŠ”
{{ "tools": ["tech_writer"] }}                                                                                                                                                                       
""")
tool_selector_chain = tool_selector_prompt | llm

def tool_selector(state: PlanExecute):
    # 1) LLM ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°›ê³ 
    response = tool_selector_chain.invoke({"query": state.input})
    raw = response.content.strip()

    try:
        # 2) extract_json_from_text ë¡œ JSON ë©ì–´ë¦¬ë§Œ ì¶”ì¶œ
        json_text = extract_json_from_text(raw)
        parsed = json.loads(json_text)
    except Exception as e:
        # 3) ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹…ì„ ìœ„í•´ ì›ë³¸ ì‘ë‹µ ë‚¨ê¸°ê¸°
        raise ValueError(
            f"[tool_selector] JSON íŒŒì‹± ì‹¤íŒ¨: {e}\n"
            f"ì›ë³¸ ì‘ë‹µ:\n{raw}"
        )

    # 4) ì˜ íŒŒì‹±ëœ tools ë¦¬ìŠ¤íŠ¸ë¡œ ìƒíƒœ ê°±ì‹ 
    return {
        "tools": parsed["tools"],
        "log": state.log + [f"ğŸ”§ ì„ íƒëœ ë„êµ¬: {parsed['tools']}"]
    }

# âœ… Sub-query Planner
sub_query_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì„ íƒëœ ë„êµ¬ ëª©ë¡ì…ë‹ˆë‹¤.
ê° ë„êµ¬ì— ëŒ€í•´ í•˜ë‚˜ì˜ ì§ˆì˜ë¥¼ ìƒì„±í•˜ì„¸ìš”. 
ë‹¨,
- patent_searcherëŠ” ì§ˆë¬¸ì„ ë°˜ì˜í•˜ì—¬ ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ ì „ë‹¬, ì´ë•Œ ì‚¬ìš©ìê°€ ê¸°ìˆ ì ì¸ ë‚´ìš©ì„ ë‹´ê¸°ì— ë‚´ìš©ì„ ì„ì˜ëŒ€ë¡œ ëˆ„ë½í•˜ì§€ ì•Šì•˜ìœ¼ë©´ í•´. **ê·¸ë¦¬ê³ **, **ë˜ëŠ”** ë° ë§ˆì¹¨í‘œ ì½¤ë§ˆë¡œ êµ¬ë¶„í•´ì„œ ë‘ ê°€ì§€ ê¸°ìˆ ì— ëŒ€í•´ì„œ ì§ˆë¬¸ì„ í•˜ëŠ” ê²½ìš°ëŠ” ë‚˜ëˆ„ì–´ì„œ íŒŒì•…í•´.
- patent_trend_analyzerëŠ” '**íŠ¹í—ˆ ì¶œì› ë™í–¥ ë¶„ì„**'ì„ ìœ„í•´ ì‚¬ìš©ì sub queryì— ìˆëŠ” í‚¤ì›Œë“œ ë‹¨ì–´ì™€ ì—°ë„ë¥¼ ì‚¬ìš©í•´ì„œ ì „ë‹¬ (ì˜ˆ1: êµ¬ë™ëª¨í„° ê´€ë ¨ 2020ë…„ ì´í›„ ì¶œì› ë™í–¥. ì˜ˆ2: í˜„ëŒ€ìë™ì°¨ì˜ ë°°í„°ë¦¬ ê´€ë ¨ ì—°ë„ë³„ ì¶œì›ë™í–¥.)
- patent_evaluatorëŠ” ê²½ìŸì‚¬ ë° íŠ¹ì • ê¸°ìˆ ì— ëŒ€í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œë¥¼ 1~2ê°œ ì‚¬ìš©í•´ì„œ ì „ë‹¬. ì´ë•Œ í‚¤ì›Œë“œëŠ” ê¸°ìˆ  ë‹¨ìœ„ì—¬ì•¼ í•˜ê³  ìì—°ì–´ í˜•íƒœë¡œ ì „ë‹¬í•´ì•¼ í•¨.
- tech_writerëŠ” "ì´ˆì•ˆì‘ì„±" ì´ë¼ê³  ì „ë‹¬.

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{query}"

ì„ íƒëœ ë„êµ¬ ëª©ë¡:
{tools}

ë³µí•© ì§ˆì˜ì˜ ê²½ìš° ì¶œë ¥ ì˜ˆì‹œ:

1) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ì˜ ë°°í„°ë¦¬ íš¨ìœ¨ ê°œì„  ê¸°ìˆ  ê´€ë ¨ íŠ¹í—ˆìˆì–´? ê´€ë ¨ ê¸°ìˆ ì— ëŒ€í•œ ì—°ë„ë³„ ì¶œì› ë™í–¥ë„ ì•Œë ¤ì¤˜"ë¼ë©´,  
{{ '{{' }}
  "sub_queries": {{ '{' }}
    "patent_searcher": "ì „ê¸°ì°¨ì˜ ë°°í„°ë¦¬ íš¨ìœ¨ ê°œì„  ê¸°ìˆ  ê´€ë ¨ íŠ¹í—ˆ",
    "patent_trend_analyzer": "ì „ê¸°ì°¨ ê³¼ì—´ ë°©ì§€ ê´€ë ¨ ì—°ë„ë³„ ì¶œì› ë™í–¥"
  {{ '}' }}
{{ '}}' }}

2) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ ë‚´ ëƒ‰ê°ìˆ˜ íë¦„ì„ ì œì–´í•˜ê¸° ìœ„í•´ êµ¬ì¶•í•œ ìë™ ëª¨ë‹ˆí„°ë§ ê¸°ìˆ ì„ ì•Œê³  ì‹¶ê³  ì—´ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë‚´ë¶€ ì¿¨ë§ì‹œìŠ¤í…œì„ ì´ìš©í•˜ëŠ” ê¸°ìˆ ì„ ì•Œê³  ì‹¶ë‹¤" ê³  í•œë‹¤ë©´,  
{{ '{{' }}
  "sub_queries": {{ '{' }}
    "patent_searcher": "ì „ê¸°ì°¨ ë‚´ ëƒ‰ê°ìˆ˜ íë¦„ì„ ì œì–´í•˜ê¸° ìœ„í•´ êµ¬ì¶•í•œ ìë™ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê¸°ìˆ , ì—´ ê´€ë¦¬ë¥¼ ìœ„í•œ ì°¨ì²´ ë‚´ ì¿¨ë§ ì‹œìŠ¤í…œì„ ì´ìš©í•˜ëŠ” ê¸°ìˆ "
  {{ '}' }}
{{ '}}' }}

3) ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ "ì „ê¸°ì°¨ì˜ ë³€ì†ê°ì„ ì¢‹ê²Œ í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ íŠ¹í—ˆ ìˆì–´? ê´€ë ¨ ê¸°ìˆ ì„ ì¶œì›í•œ í˜„ëŒ€ìë™ì°¨ì˜ íŠ¹í—ˆ í‰ê°€ë¥¼ í•´ì¤˜"ë¼ë©´,  
{{ '{{' }}
  "sub_queries": {{ '{' }}
    "patent_searcher": "ë³€ì†ê°ì„ ì£¼ë©° ìŠ¹ì°¨ê°ì„ ë†’ì¸ ê¸°ìˆ ",
    "patent_evaluator": "ë³€ì†ê° ë° ì†ë„ ì œì–´"
  {{ '}' }}
{{ '}}' }}
""", template_format="jinja2")

sub_query_chain = sub_query_prompt | llm

def tool_query_planner(state: PlanExecute):
    # âœ… ì´ë¯¸ ë¶„ë¦¬ë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    if state.sub_queries_generated:
        return {
            "sub_queries": state.sub_queries,
            "log": state.log + ["âœ… Sub-query ì´ë¯¸ ìƒì„±ë¨, ì¬ìƒì„±í•˜ì§€ ì•ŠìŒ"]
        }

    tools_str = ", ".join(state.tools)
    result = sub_query_chain.invoke({"query": state.input, "tools": tools_str})

    try:
        json_text = extract_json_from_text(result.content)
        parsed = json.loads(json_text)
    except Exception as e:
        raise ValueError(f"âŒ Sub-query ìƒì„± ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:\n{result.content}\n\nì—ëŸ¬: {e}")

    return {
        "sub_queries": parsed["sub_queries"],
        "sub_queries_generated": True,  # âœ… ìƒíƒœê°’ ê°±ì‹ 
        "log": state.log + [f"ğŸ§© Sub-query ë¶„ë¦¬ ê²°ê³¼: {parsed['sub_queries']}"]
    }

# âœ… Tool ì‹¤í–‰ê¸°
def execute_tools(state: PlanExecute):
    results = {}
    for tool_name, query in state.sub_queries.items():
        if tool_name == "patent_searcher":
            sub_queries = [q.strip() for q in query.split(",") if q.strip()]  # ì‰¼í‘œ ê¸°ì¤€ ë¶„ë¦¬
            combined_summary = ""
            for i, sub_q in enumerate(sub_queries, 1):
                # print(f"\nğŸ” [Tool1-{i}] ì„œë¸Œ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘: {sub_q}")
                summary, _ = run_filtered_rag(vectorstore, embedding_model, sub_q, llm=state.llm, use_bm25=True)
                combined_summary += f"[ì„œë¸Œ ì¿¼ë¦¬ {i}] {sub_q}\n{summary}\n\n"
            results[tool_name] = combined_summary.strip()


        elif tool_name == "patent_trend_analyzer":
            trend_agent = KeywordAnalyzer(csv_path="/Users/heejinyang/python/streamlit/Codes/0527_cleaning_processing_ver1.csv", llm=state.llm)
            intepretation = trend_agent.run(query) 
            results[tool_name] = safe_result_summary(intepretation)
        elif tool_name == "patent_evaluator":
            evaluator = Agent3(
                csv_path="/Users/heejinyang/python/streamlit/Codes/0527_cleaning_processing_ver1.csv",
                llm=state.llm
            )
            interpretation = evaluator.handle(topic_query=query)
            results[tool_name] = interpretation  # ë°”ë¡œ ì‹œì‚¬ì  ê²°ê³¼ ì €ì¥
        elif tool_name == "tech_writer":
            print("ğŸ“ ê¸°ìˆ  ì„¤ëª…ì„œë¥¼ ìœ„í•œ ì´ˆì•ˆ ì‘ì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            result = generate_technical_draft.invoke({"user_input": query})
    
            # LangChain LLM ì‘ë‹µ ê°ì²´ì¼ ê²½ìš° .content ì¶”ì¶œ
            content = result.content if hasattr(result, "content") else str(result)
            results[tool_name] = content        
        else:
            results[tool_name] = f"[{tool_name}]ì— ëŒ€í•œ ì‘ë‹µ (Mock ì²˜ë¦¬ë¨)"
            
    return {
        "results": results,
        "log": state.log + [f"âš™ï¸ ì‹¤í–‰ ì™„ë£Œ: {list(results.keys())}"]
    }

# âœ… ê²°ê³¼ ìš”ì•½ê¸°
def post_summary(state: PlanExecute):
    merged = "\n\n".join(f"[{tool} ê²°ê³¼]\n{res}" for tool, res in state.results.items())
    
    if not merged.strip():
        return {
            "response": "â— ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.",
            "log": state.log + ["âš ï¸ post_summary: ê²°ê³¼ ì—†ìŒ"]
        }
        
    summary_prompt = PromptTemplate.from_template("""
ì•„ë˜ëŠ” ê° ë„êµ¬ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ê²°ê³¼ì…ë‹ˆë‹¤:

{merged}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
ì´ë•Œ, ê° Toolì— ë”°ë¼ ì–´ë–¤ ì •ë³´ê°€ íŒŒì•…ë˜ì—ˆëŠ”ì§€, ì´ë¥¼ í†µí•´ ì–´ë–¤ ì¢…í•©ì  ì‹œì‚¬ì ì„ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ì˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë‹¨,ë‹¤ë¥¸ ì–¸ì–´ë¼ë©´ **ë°˜ë“œì‹œ** í•œêµ­ì–´ë¡œ ë³€í™˜í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”.
""")
    summary_chain = summary_prompt | state.llm
    result = summary_chain.invoke({"merged": merged})
    return {
        "response": result.content.strip(),
        "log": state.log + ["ğŸ§  ìµœì¢… ì¢…í•© ìš”ì•½ ì™„ë£Œ"]
    }

# âœ… LangGraph êµ¬ì„±
graph = StateGraph(PlanExecute)
graph.add_node("tool_selector", tool_selector)
graph.add_node("tool_query_planner", tool_query_planner)
graph.add_node("execute", execute_tools)
graph.add_node("post_summary", post_summary)

graph.add_edge(START, "tool_selector")
graph.add_edge("tool_selector", "tool_query_planner")
graph.add_edge("tool_query_planner", "execute")
graph.add_edge("execute", "post_summary")
graph.add_edge("post_summary", END)

app = graph.compile(checkpointer=MemorySaver())
